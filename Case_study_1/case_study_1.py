# -*- coding: utf-8 -*-
"""Case_Study_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/117c8PE_kA-wq8ax30fmBVrBrvXCqvvtR
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
from sklearn import metrics
from itertools import combinations
from scipy.stats import pearsonr, zscore

import torch
import torch.nn as nn
import torch.optim as optim

from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense

device= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print('Using.. ',device)

df = pd.read_csv('loans_full_schema.csv')

df.head()

df.info()

df1 = df.pop('interest_rate')
df['interest_rate'] = df1

lst =[]
for col in df.columns:
  if len(df[col].unique())<3:
    lst.append(col)
print(lst)

df.drop(['num_accounts_120d_past_due'], axis=1, inplace=True) #since only one value in the column

zero_col = ['emp_length','debt_to_income', 'annual_income_joint','debt_to_income_joint','months_since_last_delinq','months_since_90d_late','months_since_last_credit_inquiry']
empty_col = ['emp_title','verification_income_joint',]
df[zero_col] = df[zero_col].fillna(0)
df[empty_col] = df[empty_col].fillna('')

num_feat = df.select_dtypes('number').columns.values
comb_num_feat = np.array(list(combinations(num_feat, 2)))
corr_num_feat = np.array([])
for comb in comb_num_feat:
    corr = pearsonr(df[comb[0]], df[comb[1]])[0]
    corr_num_feat = np.append(corr_num_feat, corr)
high_corr_num = comb_num_feat[np.abs(corr_num_feat) >= 0.8]                     #source: pavlo fesenko (https://www.kaggle.com/code/pavlofesenko/minimizing-risks-for-loan-investment)
df = df.drop(np.unique(high_corr_num[:, 1]), axis=1, errors='ignore')

df.info()

plt.figure(figsize=(20,10))
sns.countplot(data=df,x='loan_status',hue='term')
plt.xlabel('Loan Status')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(20,10))
grade = sorted(df.grade.unique())
status = df[df['loan_status'].isin(df.loan_status.unique()[:2])]
sns.countplot(x='grade', data=status, hue='loan_status', order=grade)
plt.show()

plt.figure(figsize=(20,10))
grade = sorted(df.grade.unique())
status = df[df['loan_status'].isin(df.loan_status.unique()[2:])]
sns.countplot(x='grade', data=status, hue='loan_status', order=grade)
plt.show()

plt.figure(figsize=(20,10))
sns.boxplot(data=df, x='grade', y='interest_rate',order=grade)
plt.ylabel('Interest rate')
plt.show()

plt.figure(figsize=(15,7))
sns.countplot(x='homeownership', data=df)#, hue='interest_rate')
plt.show()

plt.figure(figsize=(20,10))
sns.boxplot(data=df, x='homeownership', y='interest_rate')
plt.ylabel('Interest rate')
plt.show()

plt.figure(figsize=(15,7))
sns.countplot(x='term', data=df)#, hue='interest_rate')
plt.show()

plt.figure(figsize=(15,7))
sns.boxplot(data=df, x='term', y='interest_rate')
plt.ylabel('Interest rate')
plt.show()

order = df.emp_length.unique().sort()
plt.figure(figsize=(20,10))
sns.boxplot(data=df, x='emp_length', y='interest_rate', order=order)
plt.ylabel('Interest rate')
plt.show()

plt.figure(figsize=(20,10))
sns.scatterplot(data=df[df['annual_income']<1.0e6], x="loan_amount", y="interest_rate", hue="grade", style="term")
plt.show()

plt.figure(figsize=(20,10))
sns.scatterplot(data=df, x="total_credit_lines", y="interest_rate", hue="grade", style="term")
plt.show()

plt.figure(figsize=(20,10))
sns.scatterplot(data=df[df['annual_income']<1.0e6], x="annual_income", y="interest_rate", hue="homeownership")#, style="issue_month")
plt.show()

plt.figure(figsize=(20,10))
sns.scatterplot(data=df[(df['annual_income']<1.0e6)], x="annual_income", y="interest_rate", hue="loan_purpose", style="disbursement_method")
plt.show()

order = df.groupby('loan_purpose').agg({'interest_rate': ['mean']})['interest_rate'].sort_values(by='mean').index
plt.figure(figsize=(20,10))
sns.boxplot(data=df, x='loan_purpose', y='interest_rate', order=order)
plt.ylabel('Interest rate')
plt.show()

plt.figure(figsize=(20,10))
sns.scatterplot(data=df[df['annual_income']<0.6e6], x="loan_amount", y="interest_rate", hue="verified_income", style="initial_listing_status")
plt.show()

#removing outliers
df = df[(df.annual_income<df.annual_income.mean()+3*df.annual_income.std())]
df = df[~((df.grade == 'D') & (df.interest_rate < 10))]

#remove outliers

# df = df[(np.abs(zscore(df[df.select_dtypes('number').columns.values])) < 3).all(axis=1)]

#converting object columns to numerical
cat_col = df.select_dtypes('object').columns.values
for col in cat_col:
  tmepdf = df[col].copy()
  s= tmepdf.value_counts()
  s = s[s<10]
  df.loc[df[col].isin(s.index), col] = ''
  le = LabelEncoder()
  df[col] = le.fit_transform(df[col])

plt.figure(figsize=(20,10))
sns.heatmap(df.corr(), vmin=-1, vmax=1, center=0)
plt.show()

combs = np.array(list(combinations(df.columns.values[:-1], 2)))
corrs = np.array([])
for comb in combs:
    corr = pearsonr(df[comb[0]], df[comb[1]])[0]
    corrs = np.append(corrs, corr)
high_corr= combs[np.abs(corrs) >= 0.8]
df = df.drop(np.unique(high_corr[:, 0]), axis=1, errors='ignore')               #source: pavlo fesenko (https://www.kaggle.com/code/pavlofesenko/minimizing-risks-for-loan-investment)

X = df.iloc[:,:-1]
y = df.iloc[:,-1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
sc = StandardScaler()
y_train = sc.fit_transform(y_train.reshape(-1,1))
y_test = sc.transform(y_test.reshape(-1,1))

rf = RandomForestRegressor(n_estimators=100, random_state = 42)
rf.fit(X_train, y_train.reshape(-1,))

y_pred = rf.predict(X_test)
y_pred = sc.inverse_transform(y_pred.reshape(-1,1))

error = metrics.mean_squared_error(sc.inverse_transform(y_test), y_pred, squared=False)
print('Root Mean Squared Error: ',round(error,3))
print('Mean Absolute Error: ',round(metrics.mean_absolute_error(sc.inverse_transform(y_test), y_pred),3))

plt.figure(figsize=(20,10))
plt.scatter(y=sc.inverse_transform(y_test),x=range(len(sc.inverse_transform(y_test))),label='Actual')
plt.scatter(y=y_pred,x=range(len(sc.inverse_transform(y_test))),label='Predicted')
plt.title('Predictions using Random Forest')
plt.xlabel('Datapoint Number')
plt.ylabel('Interest rate')
plt.legend()
plt.show()

col = X_train.columns
imp = rf.feature_importances_
imp_df = pd.DataFrame({'Attributes': col, 'Importance': imp})
imp_df = imp_df.sort_values('Importance', ascending=False)[:5]
plt.figure(figsize=(15,7))
sns.barplot(x='Importance', y='Attributes', data=imp_df)
plt.show()

regressor = Sequential()
regressor.add(Dense(100, input_dim=41, kernel_initializer='normal', activation='relu'))
regressor.add(Dense(20, kernel_initializer='normal', activation='relu'))
regressor.add(Dense(1, kernel_initializer='normal'))
regressor.compile(optimizer = 'adam', loss = 'mean_absolute_error')
regressor.summary()

sc_ann = StandardScaler()
X_train = sc_ann.fit_transform(X_train)
X_test = sc_ann.transform(X_test)

history = regressor.fit(X_train, y_train, epochs = 20, batch_size = 32, validation_data=(X_test, y_test))

plt.figure(figsize=(15,7))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

y_pred = regressor.predict(X_test)
error = metrics.mean_squared_error(sc.inverse_transform(y_test), sc.inverse_transform(y_pred), squared=False)
print('Root Mean Squared Error: ',round(error,3))
print('Mean Absolute Error: ',round(metrics.mean_absolute_error(sc.inverse_transform(y_test), sc.inverse_transform(y_pred)),3))

plt.figure(figsize=(20,10))
plt.scatter(y=sc.inverse_transform(y_test),x=range(len(sc.inverse_transform(y_test))),label='Actual')
plt.scatter(y=sc.inverse_transform(y_pred),x=range(len(sc.inverse_transform(y_test))),label='Predicted')
plt.title('Predictions using Artificial Neural Network')
plt.xlabel('Datapoint Number')
plt.ylabel('Interest rate')
plt.legend()
plt.show()